#blocked = #ttg.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [8], order = [0]}>
#loc = loc("/home/zhouxulin/intern/triton/python/tutorials/02-fused-softmax.py":83:0)
#loc1 = loc(unknown)
#loc12 = loc("/home/zhouxulin/intern/triton/python/tutorials/02-fused-softmax.py":99:37)
#loc17 = loc("/home/zhouxulin/intern/triton/python/tutorials/02-fused-softmax.py":102:29)
#shared = #ttg.shared<{vec = 1, perPhase = 1, maxPhase = 1, order = [0], hasLeadingOffset = false}>
#loc26 = loc(callsite(#loc1 at #loc12))
#loc29 = loc(callsite(#loc1 at #loc17))
module attributes {"ttg.num-ctas" = 1 : i32, "ttg.num-warps" = 8 : i32, ttg.target = "cuda:86", "ttg.threads-per-warp" = 32 : i32} {
  tt.func public @softmax_kernel(%arg0: !tt.ptr<f32> {tt.divisibility = 16 : i32} loc("/home/zhouxulin/intern/triton/python/tutorials/02-fused-softmax.py":83:0), %arg1: !tt.ptr<f32> {tt.divisibility = 16 : i32} loc("/home/zhouxulin/intern/triton/python/tutorials/02-fused-softmax.py":83:0), %arg2: i32 {tt.divisibility = 16 : i32} loc("/home/zhouxulin/intern/triton/python/tutorials/02-fused-softmax.py":83:0), %arg3: i32 {tt.divisibility = 16 : i32} loc("/home/zhouxulin/intern/triton/python/tutorials/02-fused-softmax.py":83:0), %arg4: i32 {tt.divisibility = 16 : i32} loc("/home/zhouxulin/intern/triton/python/tutorials/02-fused-softmax.py":83:0), %arg5: i32 {tt.divisibility = 16 : i32} loc("/home/zhouxulin/intern/triton/python/tutorials/02-fused-softmax.py":83:0)) attributes {noinline = false} {
    %c1_i32 = arith.constant 1 : i32 loc(#loc1)
    %c0_i32 = arith.constant 0 : i32 loc(#loc1)
    %c-1_i32 = arith.constant -1 : i32 loc(#loc1)
    %cst = arith.constant dense<0xFF800000> : tensor<256xf32, #blocked> loc(#loc1)
    %0 = tt.get_program_id x : i32 loc(#loc2)
    %1 = tt.get_num_programs x : i32 loc(#loc3)
    %2 = tt.make_range {end = 256 : i32, start = 0 : i32} : tensor<256xi32, #blocked> loc(#loc4)
    %3 = tt.splat %arg5 : i32 -> tensor<256xi32, #blocked> loc(#loc5)
    %4 = arith.cmpi slt, %2, %3 : tensor<256xi32, #blocked> loc(#loc5)
    %5 = ttg.local_alloc  : () -> !ttg.memdesc<1x256xf32, #shared, #ttg.shared_memory, mutable> loc(#loc6)
    %6 = arith.cmpi slt, %0, %arg4 : i32 loc(#loc7)
    %7 = arith.muli %0, %arg2 : i32 loc(#loc8)
    %8 = tt.addptr %arg1, %7 : !tt.ptr<f32>, i32 loc(#loc9)
    %9 = tt.splat %8 : !tt.ptr<f32> -> tensor<256x!tt.ptr<f32>, #blocked> loc(#loc10)
    %10 = tt.addptr %9, %2 : tensor<256x!tt.ptr<f32>, #blocked>, tensor<256xi32, #blocked> loc(#loc10)
    %11 = ttg.memdesc_subview %5[%c0_i32, %c0_i32] : !ttg.memdesc<1x256xf32, #shared, #ttg.shared_memory, mutable> -> !ttg.memdesc<256xf32, #shared, #ttg.shared_memory, mutable> loc(#loc6)
    %12 = tt.splat %6 : i1 -> tensor<256xi1, #blocked> loc(#loc7)
    %13 = arith.andi %12, %4 : tensor<256xi1, #blocked> loc(#loc7)
    %14 = ttg.async_copy_global_to_local %10, %11 mask %13 other %cst : tensor<256x!tt.ptr<f32>, #blocked> -> <256xf32, #shared, #ttg.shared_memory, mutable> loc(#loc6)
    %15 = ttg.async_commit_group %14 loc(#loc6)
    %16:3 = scf.for %arg6 = %0 to %arg4 step %1 iter_args(%arg7 = %c0_i32, %arg8 = %c-1_i32, %arg9 = %15) -> (i32, i32, !ttg.async.token)  : i32 {
      %18 = arith.subi %arg4, %1 : i32 loc(#loc7)
      %19 = arith.cmpi slt, %arg6, %18 : i32 loc(#loc7)
      %20 = arith.addi %arg8, %c1_i32 : i32 loc(#loc7)
      %21 = arith.cmpi slt, %20, %c1_i32 : i32 loc(#loc7)
      %22 = arith.select %21, %20, %c0_i32 : i32 loc(#loc7)
      %23 = ttg.async_wait %arg9 {num = 0 : i32} loc(#loc6)
      %24 = ttg.memdesc_subview %5[%22, %c0_i32] : !ttg.memdesc<1x256xf32, #shared, #ttg.shared_memory, mutable> -> !ttg.memdesc<256xf32, #shared, #ttg.shared_memory, mutable> loc(#loc6)
      %25 = ttg.local_load %24 token %23 : !ttg.memdesc<256xf32, #shared, #ttg.shared_memory, mutable> -> tensor<256xf32, #blocked> loc(#loc6)
      %26 = arith.select %4, %25, %cst : tensor<256xi1, #blocked>, tensor<256xf32, #blocked> loc(#loc6)
      %27 = "tt.reduce"(%26) <{axis = 0 : i32}> ({
      ^bb0(%arg10: f32 loc(callsite(#loc1 at #loc12)), %arg11: f32 loc(callsite(#loc1 at #loc12))):
        %51 = arith.maxnumf %arg10, %arg11 : f32 loc(#loc31)
        tt.reduce.return %51 : f32 loc(#loc25)
      }) : (tensor<256xf32, #blocked>) -> f32 loc(#loc25)
      %28 = tt.splat %27 : f32 -> tensor<256xf32, #blocked> loc(#loc14)
      %29 = arith.subf %26, %28 : tensor<256xf32, #blocked> loc(#loc14)
      %30 = math.exp %29 : tensor<256xf32, #blocked> loc(#loc15)
      %31 = "tt.reduce"(%30) <{axis = 0 : i32}> ({
      ^bb0(%arg10: f32 loc(callsite(#loc1 at #loc17)), %arg11: f32 loc(callsite(#loc1 at #loc17))):
        %51 = arith.addf %arg10, %arg11 : f32 loc(#loc32)
        tt.reduce.return %51 : f32 loc(#loc28)
      }) : (tensor<256xf32, #blocked>) -> f32 loc(#loc28)
      %32 = tt.splat %31 : f32 -> tensor<256xf32, #blocked> loc(#loc19)
      %33 = arith.divf %30, %32 : tensor<256xf32, #blocked> loc(#loc19)
      %34 = arith.muli %arg6, %arg3 : i32 loc(#loc20)
      %35 = tt.addptr %arg0, %34 : !tt.ptr<f32>, i32 loc(#loc21)
      %36 = tt.splat %35 : !tt.ptr<f32> -> tensor<256x!tt.ptr<f32>, #blocked> loc(#loc22)
      %37 = tt.addptr %36, %2 : tensor<256x!tt.ptr<f32>, #blocked>, tensor<256xi32, #blocked> loc(#loc22)
      tt.store %37, %33, %4 : tensor<256x!tt.ptr<f32>, #blocked> loc(#loc23)
      %38 = arith.addi %arg7, %c1_i32 : i32 loc(#loc7)
      %39 = arith.cmpi slt, %38, %c1_i32 : i32 loc(#loc7)
      %40 = arith.select %39, %38, %c0_i32 : i32 loc(#loc7)
      %41 = arith.addi %arg6, %1 : i32 loc(#loc7)
      %42 = arith.muli %41, %arg2 : i32 loc(#loc8)
      %43 = tt.addptr %arg1, %42 : !tt.ptr<f32>, i32 loc(#loc9)
      %44 = tt.splat %43 : !tt.ptr<f32> -> tensor<256x!tt.ptr<f32>, #blocked> loc(#loc10)
      %45 = tt.addptr %44, %2 : tensor<256x!tt.ptr<f32>, #blocked>, tensor<256xi32, #blocked> loc(#loc10)
      %46 = ttg.memdesc_subview %5[%40, %c0_i32] : !ttg.memdesc<1x256xf32, #shared, #ttg.shared_memory, mutable> -> !ttg.memdesc<256xf32, #shared, #ttg.shared_memory, mutable> loc(#loc6)
      %47 = tt.splat %19 : i1 -> tensor<256xi1, #blocked> loc(#loc7)
      %48 = arith.andi %47, %4 : tensor<256xi1, #blocked> loc(#loc7)
      %49 = ttg.async_copy_global_to_local %45, %46 mask %48 other %cst : tensor<256x!tt.ptr<f32>, #blocked> -> <256xf32, #shared, #ttg.shared_memory, mutable> loc(#loc6)
      %50 = ttg.async_commit_group %49 loc(#loc6)
      scf.yield %40, %22, %50 : i32, i32, !ttg.async.token loc(#loc7)
    } {tt.num_stages = 2 : i32} loc(#loc7)
    %17 = ttg.async_wait  {num = 0 : i32} loc(#loc7)
    ttg.local_dealloc %5 : !ttg.memdesc<1x256xf32, #shared, #ttg.shared_memory, mutable> loc(#loc7)
    tt.return loc(#loc24)
  } loc(#loc)
} loc(#loc)
#loc2 = loc("/home/zhouxulin/intern/triton/python/tutorials/02-fused-softmax.py":86:30)
#loc3 = loc("/home/zhouxulin/intern/triton/python/tutorials/02-fused-softmax.py":87:31)
#loc4 = loc("/home/zhouxulin/intern/triton/python/tutorials/02-fused-softmax.py":93:35)
#loc5 = loc("/home/zhouxulin/intern/triton/python/tutorials/02-fused-softmax.py":96:29)
#loc6 = loc("/home/zhouxulin/intern/triton/python/tutorials/02-fused-softmax.py":97:22)
#loc7 = loc("/home/zhouxulin/intern/triton/python/tutorials/02-fused-softmax.py":88:57)
#loc8 = loc("/home/zhouxulin/intern/triton/python/tutorials/02-fused-softmax.py":90:46)
#loc9 = loc("/home/zhouxulin/intern/triton/python/tutorials/02-fused-softmax.py":90:36)
#loc10 = loc("/home/zhouxulin/intern/triton/python/tutorials/02-fused-softmax.py":94:37)
#loc11 = loc("/home/zhouxulin/intern/triton/python/triton/language/standard.py":184:40)
#loc13 = loc("/home/zhouxulin/intern/triton/python/triton/language/standard.py":163:27)
#loc14 = loc("/home/zhouxulin/intern/triton/python/tutorials/02-fused-softmax.py":99:30)
#loc15 = loc("/home/zhouxulin/intern/triton/python/tutorials/02-fused-softmax.py":101:27)
#loc16 = loc("/home/zhouxulin/intern/triton/python/triton/language/standard.py":267:36)
#loc18 = loc("/home/zhouxulin/intern/triton/python/triton/language/standard.py":256:15)
#loc19 = loc("/home/zhouxulin/intern/triton/python/tutorials/02-fused-softmax.py":103:37)
#loc20 = loc("/home/zhouxulin/intern/triton/python/tutorials/02-fused-softmax.py":105:54)
#loc21 = loc("/home/zhouxulin/intern/triton/python/tutorials/02-fused-softmax.py":105:44)
#loc22 = loc("/home/zhouxulin/intern/triton/python/tutorials/02-fused-softmax.py":106:45)
#loc23 = loc("/home/zhouxulin/intern/triton/python/tutorials/02-fused-softmax.py":107:30)
#loc24 = loc("/home/zhouxulin/intern/triton/python/tutorials/02-fused-softmax.py":88:4)
#loc25 = loc(callsite(#loc11 at #loc12))
#loc27 = loc(callsite(#loc13 at #loc11))
#loc28 = loc(callsite(#loc16 at #loc17))
#loc30 = loc(callsite(#loc18 at #loc16))
#loc31 = loc(callsite(#loc27 at #loc12))
#loc32 = loc(callsite(#loc30 at #loc17))
